{
    "version": "0.0.1",
    "name": "ExtensityAI/llamacpp",
    "description": "Running a Llama server as a Neuro-Symbolic backend. This backend is a wrapper around the LlamaCpp project.",
    "expressions": [
        {
            "module": "src/engine",
            "type": "LLaMACppClientEngine"
        },
        {
            "module": "src/config",
            "type": "EngineConfig"
        }
    ],
    "run": {
        "module": "src/config",
        "type": "EngineConfig"
    },
    "dependencies": []
}